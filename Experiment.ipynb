{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9268954,"sourceType":"datasetVersion","datasetId":5608946}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n%pip install -U bitsandbytes\n%pip install -U transformers\n%pip install -U accelerate\n%pip install -U peft\n%pip install -U trl\n%pip install -U wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom tqdm import tqdm\nimport bitsandbytes as bnb\nimport torch\nimport torch.nn as nn\nimport transformers\nfrom datasets import Dataset\nfrom peft import LoraConfig, PeftConfig\nfrom trl import SFTTrainer\nfrom transformers import (AutoModelForCausalLM, \n                          AutoTokenizer, \n                          BitsAndBytesConfig, \n                          TrainingArguments, \n                          pipeline, \n                          logging)\nfrom sklearn.metrics import (accuracy_score, \n                             classification_report, \n                             confusion_matrix)\nfrom sklearn.model_selection import train_test_split\n\n# Load your dataset\ntrain_data = pd.read_csv('/kaggle/input/bengali-hate/RawData.csv')\ntest_data = pd.read_csv('/kaggle/input/bengali-hate/testing_data.csv')\n\n# Shuffle the DataFrame\ntrain_data = train_data.sample(frac=1, random_state=85)\n\n# Split the training data into training and validation sets\ntrain_data, val_data = train_test_split(train_data, test_size=0.1, random_state=85)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the prompt generation functions\ndef generate_prompt(data_point):\n    return f\"\"\"\n            Classify the text into Hate Speech, Normal Speech and return the answer as the corresponding Sentiment label.\ntext: {data_point[\"comment\"]}\nlabel: {data_point[\"Sentiment\"]}\"\"\".strip()\n\ndef generate_test_prompt(data_point):\n    return f\"\"\"\n            Classify the text into Hate Speech, Normal Speech  and return the answer as the corresponding Sentiment label.\ntext: {data_point[\"comment\"]}\nlabel: \"\"\".strip(\"Sentiment\")\n\n# Generate prompts for training, validation, and test data\ntrain_data.loc[:,'comment'] = train_data.apply(generate_prompt, axis=1)\nval_data.loc[:,'comment'] = val_data.apply(generate_prompt, axis=1)\n\n# Generate test prompts and extract true labels\ny_true = test_data.loc[:,'Sentiment']\ntest_data = pd.DataFrame(test_data.apply(generate_test_prompt, axis=1), columns=[\"comment\"])\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert to datasets\ntrain_dataset = Dataset.from_pandas(train_data[[\"comment\"]])\nval_dataset = Dataset.from_pandas(val_data[[\"comment\"]])\ntest_dataset = Dataset.from_pandas(test_data[[\"comment\"]])\n\nbase_model_name = \"facebook/opt-350m\"  # Example base model, replace with your desired model\n\nbnb_config = BitsAndBytesConfig(\n    load_in_8bit=True,\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model_name,\n    device_map=\"auto\",\n    torch_dtype=torch.float16,\n    quantization_config=bnb_config, \n)\n\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\n\ntokenizer = AutoTokenizer.from_pretrained(base_model_name)\ntokenizer.pad_token_id = tokenizer.eos_token_id\n\ndef predict(test, model, tokenizer):\n    y_pred = []\n    categories = [\"Hate Speech\", \"Normal Speech\"]\n    \n    for i in tqdm(range(len(test))):\n        prompt = test.iloc[i][\"comment\"]\n        pipe = pipeline(task=\"text-generation\", \n                        model=model, \n                        tokenizer=tokenizer, \n                        max_new_tokens=2, \n                        temperature=0.1)\n        \n        result = pipe(prompt)\n        answer = result[0]['generated_text'].split(\"label:\")[-1].strip()\n        \n        # Determine the predicted category\n        for category in categories:\n            if category.lower() in answer.lower():\n                y_pred.append(category)\n                break\n        else:\n            y_pred.append(\"none\")\n    \n    return y_pred\n\ndef evaluate(y_true, y_pred):\n    labels = [\"Hate Speech\", \"Normal Speech\"]\n    mapping = {label: idx for idx, label in enumerate(labels)}\n    \n    def map_func(x):\n        return mapping.get(x, -1)  # Map to -1 if not found, but should not occur with correct data\n    \n    y_true_mapped = np.vectorize(map_func)(y_true)\n    y_pred_mapped = np.vectorize(map_func)(y_pred)\n    \n    # Calculate accuracy\n    accuracy = accuracy_score(y_true=y_true_mapped, y_pred=y_pred_mapped)\n    print(f'Accuracy: {accuracy:.3f}')\n    \n    # Generate accuracy report\n    unique_labels = set(y_true_mapped)  # Get unique labels\n    \n    for label in unique_labels:\n        label_indices = [i for i in range(len(y_true_mapped)) if y_true_mapped[i] == label]\n        label_y_true = [y_true_mapped[i] for i in label_indices]\n        label_y_pred = [y_pred_mapped[i] for i in label_indices]\n        label_accuracy = accuracy_score(label_y_true, label_y_pred)\n        print(f'Accuracy for label {labels[label]}: {label_accuracy:.3f}')\n        \n    \n    class_report = classification_report(y_true=y_true_mapped, y_pred=y_pred_mapped, target_names=labels, labels=list(range(len(labels))))\n    print('\\nClassification Report:')\n    print(class_report)\n    \n    # Generate confusion matrix\n    conf_matrix = confusion_matrix(y_true=y_true_mapped, y_pred=y_pred_mapped, labels=list(range(len(labels))))\n    print('\\nConfusion Matrix:')\n    print(conf_matrix)\n\nimport bitsandbytes as bnb\n\ndef find_all_linear_names(model):\n    cls = bnb.nn.Linear8bitLt\n    lora_module_names = set()\n    for name, module in model.named_modules():\n        if isinstance(module, cls):\n            names = name.split('.')\n            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n    if 'lm_head' in lora_module_names:  # needed for 16 bit\n        lora_module_names.remove('lm_head')\n    return list(lora_module_names)\n\nmodules = find_all_linear_names(model)\nmodules\n\noutput_dir=\"/kaggle/working/\"\n\npeft_config = LoraConfig(\n    lora_alpha=16,\n    lora_dropout=0,\n    r=64,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=modules,\n)\n\ntraining_arguments = TrainingArguments(\n    output_dir=output_dir,                    \n    num_train_epochs=10,                      \n    per_device_train_batch_size=1,           \n    gradient_accumulation_steps=8,           \n    gradient_checkpointing=True,              \n    optim=\"paged_adamw_32bit\",\n    logging_steps=1,                         \n    learning_rate=2e-4,                       \n    weight_decay=0.001,\n    fp16=True,\n    bf16=False,\n    max_grad_norm=0.3,                        \n    max_steps=-1,\n    warmup_ratio=0.03,                      \n    group_by_length=False,\n    lr_scheduler_type=\"cosine\",            \n    report_to=\"wandb\",                  \n    eval_strategy=\"steps\",              \n    eval_steps = 0.2\n)\n\ntrainer = SFTTrainer(\n    model=model,\n    args=training_arguments,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    peft_config=peft_config,\n    dataset_text_field=\"comment\",\n    tokenizer=tokenizer,\n    max_seq_length=512,\n    packing=False,\n    dataset_kwargs={\n    \"add_special_tokens\": False,\n    \"append_concat_token\": False,\n    }\n)\n\ntrainer.train()\n\nimport wandb\nwandb.finish()\nmodel.config.use_cache = True\n\ntrainer.save_model(output_dir)\ntokenizer.save_pretrained(output_dir)\n\ny_pred = predict(test_dataset, model, tokenizer)\nevaluate(y_true, y_pred)","metadata":{},"execution_count":null,"outputs":[]}]}