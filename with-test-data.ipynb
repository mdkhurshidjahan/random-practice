{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-29T10:16:18.182411Z",
     "iopub.status.busy": "2024-08-29T10:16:18.182131Z",
     "iopub.status.idle": "2024-08-29T10:16:18.546906Z",
     "shell.execute_reply": "2024-08-29T10:16:18.545939Z",
     "shell.execute_reply.started": "2024-08-29T10:16:18.182379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/llama-3.1/transformers/8b-instruct/1/model.safetensors.index.json\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/1/model-00003-of-00004.safetensors\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/1/config.json\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/1/model-00001-of-00004.safetensors\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/1/README.md\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/1/USE_POLICY.md\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/1/tokenizer.json\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/1/tokenizer_config.json\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/1/model-00004-of-00004.safetensors\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/1/special_tokens_map.json\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/1/model-00002-of-00004.safetensors\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/1/generation_config.json\n",
      "/kaggle/input/shafi-vai-with-testing-data/testing_data.csv\n",
      "/kaggle/input/shafi-vai-with-testing-data/RawData.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U bitsandbytes\n",
    "%pip install -U transformers\n",
    "%pip install -U accelerate\n",
    "%pip install -U peft\n",
    "%pip install -U trl\n",
    "%%capture\n",
    "%pip install -U bitsandbytes\n",
    "%pip install -U transformers\n",
    "%pip install -U accelerate\n",
    "%pip install -U trl\n",
    "%pip install -U peft\n",
    "%pip install -U wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T10:51:22.212644Z",
     "iopub.status.busy": "2024-08-29T10:51:22.211883Z",
     "iopub.status.idle": "2024-08-29T10:51:52.952901Z",
     "shell.execute_reply": "2024-08-29T10:51:52.951819Z",
     "shell.execute_reply.started": "2024-08-29T10:51:22.212588Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "from trl import SFTTrainer\n",
    "from trl import setup_chat_format\n",
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                          pipeline, \n",
    "                          logging)\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T10:52:00.495489Z",
     "iopub.status.busy": "2024-08-29T10:52:00.494758Z",
     "iopub.status.idle": "2024-08-29T10:52:00.564360Z",
     "shell.execute_reply": "2024-08-29T10:52:00.563446Z",
     "shell.execute_reply.started": "2024-08-29T10:52:00.495447Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>এমন ভালবাসা ইসলাম সমর্থন করে না বিয়ের আগে কোন...</td>\n",
       "      <td>Hate Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>নোংরা মনমানসিকতার একটা লিমিট আছে  এখানে  এই প...</td>\n",
       "      <td>Hate Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>হারি আপ ব্রাদার  অ্যাটেনশন please believe me ...</td>\n",
       "      <td>Hate Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>এ নাটকের সবথেকে বাজে দিক হচ্ছে  এখানে বাবা মা...</td>\n",
       "      <td>Hate Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>এটা অনেক কষ্টের  আসলে মেয়েরা অনেক স্বার্থপর  ...</td>\n",
       "      <td>Hate Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2315</th>\n",
       "      <td>বসের নাটকের জন্য শুধু অপেহ্মায় থাকি\\n</td>\n",
       "      <td>Normal Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2316</th>\n",
       "      <td>ভাই নাইস নাইস  তিশা আপুকে আরো  নাইস  \\n</td>\n",
       "      <td>Normal Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2317</th>\n",
       "      <td>আজকের খুশির দিনেও কাঁদিয়ে দিলি রে ভাই কোলকাতা...</td>\n",
       "      <td>Normal Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318</th>\n",
       "      <td>অসাধারন নিশো ভাই আপনি আসলেই সেরা\\n</td>\n",
       "      <td>Normal Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2319</th>\n",
       "      <td>অনেক ভালো লাগলো   চোখে পানি এসে গেল  \\n</td>\n",
       "      <td>Normal Speech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2320 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment      Sentiment\n",
       "0      এমন ভালবাসা ইসলাম সমর্থন করে না বিয়ের আগে কোন...    Hate Speech\n",
       "1      নোংরা মনমানসিকতার একটা লিমিট আছে  এখানে  এই প...    Hate Speech\n",
       "2      হারি আপ ব্রাদার  অ্যাটেনশন please believe me ...    Hate Speech\n",
       "3      এ নাটকের সবথেকে বাজে দিক হচ্ছে  এখানে বাবা মা...    Hate Speech\n",
       "4      এটা অনেক কষ্টের  আসলে মেয়েরা অনেক স্বার্থপর  ...    Hate Speech\n",
       "...                                                 ...            ...\n",
       "2315              বসের নাটকের জন্য শুধু অপেহ্মায় থাকি\\n  Normal Speech\n",
       "2316            ভাই নাইস নাইস  তিশা আপুকে আরো  নাইস  \\n  Normal Speech\n",
       "2317   আজকের খুশির দিনেও কাঁদিয়ে দিলি রে ভাই কোলকাতা...  Normal Speech\n",
       "2318                 অসাধারন নিশো ভাই আপনি আসলেই সেরা\\n  Normal Speech\n",
       "2319            অনেক ভালো লাগলো   চোখে পানি এসে গেল  \\n  Normal Speech\n",
       "\n",
       "[2320 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/shafi-vai-with-testing-data/RawData.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T10:52:03.824505Z",
     "iopub.status.busy": "2024-08-29T10:52:03.823348Z",
     "iopub.status.idle": "2024-08-29T10:52:03.849045Z",
     "shell.execute_reply": "2024-08-29T10:52:03.848060Z",
     "shell.execute_reply.started": "2024-08-29T10:52:03.824446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>বছরের সেরা নাটক   বলতে হবে   আপনারা কি বলেন...</td>\n",
       "      <td>Normal Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>রকম মাইয়া কেও ভালোবাসতো আমারে লালা জান দিয়া...</td>\n",
       "      <td>Normal Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>নাটকটা তেমন ভালো লাগেনাইঅপ্রয়োজনীয় কথা বার্ত...</td>\n",
       "      <td>Hate Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>নিশো আর তিশা কি নাটক জগতটা পচাবে নাকি  এদের ...</td>\n",
       "      <td>Hate Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>হালারপুতে থাকেই ট্রেন্ড টপিক নিয়া যখন কিছু থ...</td>\n",
       "      <td>Hate Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>সালার পুত্র মুশফিক কুকুরের বাচ্চা</td>\n",
       "      <td>Hate Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>সালি একটা মাল ফুটকি মারতে ভালো লাগবে</td>\n",
       "      <td>Hate Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>সৃজিতকে কুত্তা দিয়ে চোদালে বুঝতে পারবে ভার্জিন...</td>\n",
       "      <td>Hate Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>হালার দেখে পুরাই মাথাই নস্ট\\n</td>\n",
       "      <td>Hate Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hate Speech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment      Sentiment\n",
       "0       বছরের সেরা নাটক   বলতে হবে   আপনারা কি বলেন...  Normal Speech\n",
       "1       রকম মাইয়া কেও ভালোবাসতো আমারে লালা জান দিয়া...  Normal Speech\n",
       "2      নাটকটা তেমন ভালো লাগেনাইঅপ্রয়োজনীয় কথা বার্ত...    Hate Speech\n",
       "3      নিশো আর তিশা কি নাটক জগতটা পচাবে নাকি  এদের ...    Hate Speech\n",
       "4      হালারপুতে থাকেই ট্রেন্ড টপিক নিয়া যখন কিছু থ...    Hate Speech\n",
       "..                                                 ...            ...\n",
       "253                  সালার পুত্র মুশফিক কুকুরের বাচ্চা    Hate Speech\n",
       "254               সালি একটা মাল ফুটকি মারতে ভালো লাগবে    Hate Speech\n",
       "255  সৃজিতকে কুত্তা দিয়ে চোদালে বুঝতে পারবে ভার্জিন...    Hate Speech\n",
       "256                      হালার দেখে পুরাই মাথাই নস্ট\\n    Hate Speech\n",
       "257                                                NaN    Hate Speech\n",
       "\n",
       "[258 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv(\"/kaggle/input/shafi-vai-with-testing-data/testing_data.csv\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T10:52:06.785794Z",
     "iopub.status.busy": "2024-08-29T10:52:06.784804Z",
     "iopub.status.idle": "2024-08-29T10:52:06.795830Z",
     "shell.execute_reply": "2024-08-29T10:52:06.794675Z",
     "shell.execute_reply.started": "2024-08-29T10:52:06.785748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hate Speech' 'Normal Speech']\n"
     ]
    }
   ],
   "source": [
    "unique_sentiments = df['Sentiment'].unique()\n",
    "print(unique_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T10:52:09.695559Z",
     "iopub.status.busy": "2024-08-29T10:52:09.695115Z",
     "iopub.status.idle": "2024-08-29T10:52:09.761004Z",
     "shell.execute_reply": "2024-08-29T10:52:09.759948Z",
     "shell.execute_reply.started": "2024-08-29T10:52:09.695519Z"
    }
   },
   "outputs": [],
   "source": [
    "# Shuffle the DataFrame and select only 3000 rows\n",
    "df = df.sample(frac=1, random_state=85)\n",
    "\n",
    "# Split the DataFrame\n",
    "train_size = 0.8\n",
    "eval_size = 0.1\n",
    "\n",
    "# Calculate sizes\n",
    "train_end = int(train_size * len(df))\n",
    "eval_end = train_end + int(eval_size * len(df))\n",
    "\n",
    "# Split the data\n",
    "X_train = df[:train_end]\n",
    "X_eval = df[train_end:eval_end]\n",
    "X_test = df1\n",
    "\n",
    "# Define the prompt generation functions\n",
    "def generate_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "            Classify the text into Hate Speech, Normal Speech and return the answer as the corresponding Sentiment label.\n",
    "text: {data_point[\"comment\"]}\n",
    "label: {data_point[\"Sentiment\"]}\"\"\".strip()\n",
    "\n",
    "def generate_test_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "            Classify the text into Hate Speech, Normal Speech  and return the answer as the corresponding Sentiment label.\n",
    "text: {data_point[\"comment\"]}\n",
    "label: \"\"\".strip(\"Sentiment\")\n",
    "\n",
    "# Generate prompts for training and evaluation data\n",
    "X_train.loc[:,'comment'] = X_train.apply(generate_prompt, axis=1)\n",
    "X_eval.loc[:,'comment'] = X_eval.apply(generate_prompt, axis=1)\n",
    "\n",
    "# Generate test prompts and extract true labels\n",
    "y_true = X_test.loc[:,'Sentiment']\n",
    "X_test = pd.DataFrame(X_test.apply(generate_test_prompt, axis=1), columns=[\"comment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T10:52:12.878750Z",
     "iopub.status.busy": "2024-08-29T10:52:12.877789Z",
     "iopub.status.idle": "2024-08-29T10:52:12.898633Z",
     "shell.execute_reply": "2024-08-29T10:52:12.897295Z",
     "shell.execute_reply.started": "2024-08-29T10:52:12.878706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "Hate Speech      1174\n",
       "Normal Speech     682\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T10:52:16.894687Z",
     "iopub.status.busy": "2024-08-29T10:52:16.893823Z",
     "iopub.status.idle": "2024-08-29T10:52:16.950970Z",
     "shell.execute_reply": "2024-08-29T10:52:16.949971Z",
     "shell.execute_reply.started": "2024-08-29T10:52:16.894638Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to datasets\n",
    "train_data = Dataset.from_pandas(X_train[[\"comment\"]])\n",
    "eval_data = Dataset.from_pandas(X_eval[[\"comment\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T10:52:23.294350Z",
     "iopub.status.busy": "2024-08-29T10:52:23.293931Z",
     "iopub.status.idle": "2024-08-29T10:53:52.479577Z",
     "shell.execute_reply": "2024-08-29T10:53:52.478567Z",
     "shell.execute_reply.started": "2024-08-29T10:52:23.294307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c898d123b1ec4e4490877888c59961eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_name = \"/kaggle/input/llama-3.1/transformers/8b-instruct/1\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"float16\",\n",
    "    quantization_config=bnb_config, \n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T10:53:57.397656Z",
     "iopub.status.busy": "2024-08-29T10:53:57.397237Z",
     "iopub.status.idle": "2024-08-29T10:53:57.924032Z",
     "shell.execute_reply": "2024-08-29T10:53:57.923005Z",
     "shell.execute_reply.started": "2024-08-29T10:53:57.397597Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T10:54:03.189091Z",
     "iopub.status.busy": "2024-08-29T10:54:03.188652Z",
     "iopub.status.idle": "2024-08-29T10:54:03.197244Z",
     "shell.execute_reply": "2024-08-29T10:54:03.195967Z",
     "shell.execute_reply.started": "2024-08-29T10:54:03.189048Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(test, model, tokenizer):\n",
    "    y_pred = []\n",
    "    categories = [\"Hate Speech\", \"Normal Speech\"]\n",
    "    \n",
    "    for i in tqdm(range(len(test))):\n",
    "        prompt = test.iloc[i][\"comment\"]\n",
    "        pipe = pipeline(task=\"text-generation\", \n",
    "                        model=model, \n",
    "                        tokenizer=tokenizer, \n",
    "                        max_new_tokens=2, \n",
    "                        temperature=0.1)\n",
    "        \n",
    "        result = pipe(prompt)\n",
    "        answer = result[0]['generated_text'].split(\"label:\")[-1].strip()\n",
    "        \n",
    "        # Determine the predicted category\n",
    "        for category in categories:\n",
    "            if category.lower() in answer.lower():\n",
    "                y_pred.append(category)\n",
    "                break\n",
    "        else:\n",
    "            y_pred.append(\"none\")\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T10:54:06.565088Z",
     "iopub.status.busy": "2024-08-29T10:54:06.564695Z",
     "iopub.status.idle": "2024-08-29T10:55:34.231604Z",
     "shell.execute_reply": "2024-08-29T10:55:34.230652Z",
     "shell.execute_reply.started": "2024-08-29T10:54:06.565049Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 258/258 [01:27<00:00,  2.94it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X_test, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T10:55:41.300080Z",
     "iopub.status.busy": "2024-08-29T10:55:41.298972Z",
     "iopub.status.idle": "2024-08-29T10:55:41.310091Z",
     "shell.execute_reply": "2024-08-29T10:55:41.309152Z",
     "shell.execute_reply.started": "2024-08-29T10:55:41.300037Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    labels = [\"Hate Speech\", \"Normal Speech\"]\n",
    "    mapping = {label: idx for idx, label in enumerate(labels)}\n",
    "    \n",
    "    def map_func(x):\n",
    "        return mapping.get(x, -1)  # Map to -1 if not found, but should not occur with correct data\n",
    "    \n",
    "    y_true_mapped = np.vectorize(map_func)(y_true)\n",
    "    y_pred_mapped = np.vectorize(map_func)(y_pred)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true=y_true_mapped, y_pred=y_pred_mapped)\n",
    "    print(f'Accuracy: {accuracy:.3f}')\n",
    "    \n",
    "    # Generate accuracy report\n",
    "    unique_labels = set(y_true_mapped)  # Get unique labels\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        label_indices = [i for i in range(len(y_true_mapped)) if y_true_mapped[i] == label]\n",
    "        label_y_true = [y_true_mapped[i] for i in label_indices]\n",
    "        label_y_pred = [y_pred_mapped[i] for i in label_indices]\n",
    "        label_accuracy = accuracy_score(label_y_true, label_y_pred)\n",
    "        print(f'Accuracy for label {labels[label]}: {label_accuracy:.3f}')\n",
    "        \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_true=y_true_mapped, y_pred=y_pred_mapped, target_names=labels, labels=list(range(len(labels))))\n",
    "    print('\\nClassification Report:')\n",
    "    print(class_report)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true=y_true_mapped, y_pred=y_pred_mapped, labels=list(range(len(labels))))\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T10:27:44.150397Z",
     "iopub.status.busy": "2024-08-29T10:27:44.149986Z",
     "iopub.status.idle": "2024-08-29T10:27:44.170067Z",
     "shell.execute_reply": "2024-08-29T10:27:44.169183Z",
     "shell.execute_reply.started": "2024-08-29T10:27:44.150358Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.364\n",
      "Accuracy for label Hate Speech: 0.038\n",
      "Accuracy for label Normal Speech: 0.871\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Hate Speech       0.60      0.04      0.07       157\n",
      "Normal Speech       0.80      0.87      0.83       101\n",
      "\n",
      "    micro avg       0.78      0.36      0.50       258\n",
      "    macro avg       0.70      0.45      0.45       258\n",
      " weighted avg       0.68      0.36      0.37       258\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 6 22]\n",
      " [ 4 88]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T10:55:59.699455Z",
     "iopub.status.busy": "2024-08-29T10:55:59.698687Z",
     "iopub.status.idle": "2024-08-29T10:56:13.410542Z",
     "shell.execute_reply": "2024-08-29T10:56:13.409337Z",
     "shell.execute_reply.started": "2024-08-29T10:55:59.699384Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in /opt/conda/lib/python3.10/site-packages (0.44.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from shap) (1.14.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from shap) (1.2.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from shap) (2.2.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /opt/conda/lib/python3.10/site-packages (from shap) (4.66.4)\n",
      "Requirement already satisfied: packaging>20.9 in /opt/conda/lib/python3.10/site-packages (from shap) (21.3)\n",
      "Requirement already satisfied: slicer==0.0.7 in /opt/conda/lib/python3.10/site-packages (from shap) (0.0.7)\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from shap) (0.58.1)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from shap) (3.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>20.9->shap) (3.1.2)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->shap) (0.41.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T10:56:13.413705Z",
     "iopub.status.busy": "2024-08-29T10:56:13.413192Z",
     "iopub.status.idle": "2024-08-29T10:56:16.140442Z",
     "shell.execute_reply": "2024-08-29T10:56:16.139203Z",
     "shell.execute_reply.started": "2024-08-29T10:56:13.413651Z"
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T10:56:41.103497Z",
     "iopub.status.busy": "2024-08-29T10:56:41.101511Z",
     "iopub.status.idle": "2024-08-29T10:56:45.410879Z",
     "shell.execute_reply": "2024-08-29T10:56:45.409951Z",
     "shell.execute_reply.started": "2024-08-29T10:56:41.103448Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length, dataset_kwargs. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "You passed a `dataset_kwargs` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709b7e39603e4f36ae96627d3b3a99bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c92bc948d4420aa8dead2a61619b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/232 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    }
   ],
   "source": [
    "import bitsandbytes as bnb\n",
    "\n",
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names:  # needed for 16 bit\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    "modules = find_all_linear_names(model)\n",
    "modules\n",
    "output_dir=\"llama-3.1-shafi-vai\"\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=modules,\n",
    ")\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,                    \n",
    "    num_train_epochs=3,                      \n",
    "    per_device_train_batch_size=1,           \n",
    "    gradient_accumulation_steps=8,           \n",
    "    gradient_checkpointing=True,              \n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    logging_steps=1,                         \n",
    "    learning_rate=2e-4,                       \n",
    "    weight_decay=0.001,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,                        \n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,                      \n",
    "    group_by_length=False,\n",
    "    lr_scheduler_type=\"cosine\",            \n",
    "    report_to=\"wandb\",                  \n",
    "    eval_strategy=\"steps\",              \n",
    "    eval_steps = 0.2\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"comment\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=512,\n",
    "    packing=False,\n",
    "    dataset_kwargs={\n",
    "    \"add_special_tokens\": False,\n",
    "    \"append_concat_token\": False,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T10:57:11.035354Z",
     "iopub.status.busy": "2024-08-29T10:57:11.034958Z",
     "iopub.status.idle": "2024-08-29T12:32:19.934764Z",
     "shell.execute_reply": "2024-08-29T12:32:19.933930Z",
     "shell.execute_reply.started": "2024-08-29T10:57:11.035317Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20240829_105731-e655xnpe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mdkhurshidjahan01-north-south-university/huggingface/runs/e655xnpe' target=\"_blank\">llama-3.1-shafi-vai</a></strong> to <a href='https://wandb.ai/mdkhurshidjahan01-north-south-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mdkhurshidjahan01-north-south-university/huggingface' target=\"_blank\">https://wandb.ai/mdkhurshidjahan01-north-south-university/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mdkhurshidjahan01-north-south-university/huggingface/runs/e655xnpe' target=\"_blank\">https://wandb.ai/mdkhurshidjahan01-north-south-university/huggingface/runs/e655xnpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "`torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='696' max='696' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [696/696 1:34:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.491300</td>\n",
       "      <td>0.764379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.478300</td>\n",
       "      <td>0.736136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.632900</td>\n",
       "      <td>0.716322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.419300</td>\n",
       "      <td>0.739342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "`torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=696, training_loss=0.5946709797128864, metrics={'train_runtime': 5707.9444, 'train_samples_per_second': 0.975, 'train_steps_per_second': 0.122, 'total_flos': 2.543503603426099e+16, 'train_loss': 0.5946709797128864, 'epoch': 3.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T12:43:41.058509Z",
     "iopub.status.busy": "2024-08-29T12:43:41.057544Z",
     "iopub.status.idle": "2024-08-29T12:43:50.231982Z",
     "shell.execute_reply": "2024-08-29T12:43:50.231181Z",
     "shell.execute_reply.started": "2024-08-29T12:43:41.058463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▄▁▄</td></tr><tr><td>eval/runtime</td><td>█▁▂▃</td></tr><tr><td>eval/samples_per_second</td><td>▁█▇▆</td></tr><tr><td>eval/steps_per_second</td><td>▁█▆▅</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>██▃▃▂▃▁▂▂▃▁▂▃▁▂▂▂▂▁▂▁▁▂▂▂▃▂▃▂▄▂▃▂▂▃▂▂▂▃▁</td></tr><tr><td>train/learning_rate</td><td>▄███████▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▃▃▂▂▂▃▃▃▂▃▂▂▁▃▂▂▂▂▂▂▂▃▂▂▂▂▂▁▂▂▂▂▁▂▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.73934</td></tr><tr><td>eval/runtime</td><td>62.7054</td></tr><tr><td>eval/samples_per_second</td><td>3.7</td></tr><tr><td>eval/steps_per_second</td><td>0.462</td></tr><tr><td>total_flos</td><td>2.543503603426099e+16</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>696</td></tr><tr><td>train/grad_norm</td><td>0.26954</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.2925</td></tr><tr><td>train_loss</td><td>0.59467</td></tr><tr><td>train_runtime</td><td>5707.9444</td></tr><tr><td>train_samples_per_second</td><td>0.975</td></tr><tr><td>train_steps_per_second</td><td>0.122</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">llama-3.1-shafi-vai</strong> at: <a href='https://wandb.ai/mdkhurshidjahan01-north-south-university/huggingface/runs/e655xnpe' target=\"_blank\">https://wandb.ai/mdkhurshidjahan01-north-south-university/huggingface/runs/e655xnpe</a><br/> View project at: <a href='https://wandb.ai/mdkhurshidjahan01-north-south-university/huggingface' target=\"_blank\">https://wandb.ai/mdkhurshidjahan01-north-south-university/huggingface</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240829_105731-e655xnpe/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.finish()\n",
    "model.config.use_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T12:44:34.501658Z",
     "iopub.status.busy": "2024-08-29T12:44:34.500924Z",
     "iopub.status.idle": "2024-08-29T12:44:36.293337Z",
     "shell.execute_reply": "2024-08-29T12:44:36.292203Z",
     "shell.execute_reply.started": "2024-08-29T12:44:34.501614Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('llama-3.1-shafi-vai/tokenizer_config.json',\n",
       " 'llama-3.1-shafi-vai/special_tokens_map.json',\n",
       " 'llama-3.1-shafi-vai/tokenizer.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T12:44:44.126752Z",
     "iopub.status.busy": "2024-08-29T12:44:44.126364Z",
     "iopub.status.idle": "2024-08-29T12:46:45.098709Z",
     "shell.execute_reply": "2024-08-29T12:46:45.097725Z",
     "shell.execute_reply.started": "2024-08-29T12:44:44.126716Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 258/258 [02:00<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.992\n",
      "Accuracy for label Hate Speech: 1.000\n",
      "Accuracy for label Normal Speech: 0.980\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Hate Speech       0.99      1.00      0.99       157\n",
      "Normal Speech       1.00      0.98      0.99       101\n",
      "\n",
      "     accuracy                           0.99       258\n",
      "    macro avg       0.99      0.99      0.99       258\n",
      " weighted avg       0.99      0.99      0.99       258\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[157   0]\n",
      " [  2  99]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X_test, model, tokenizer)\n",
    "evaluate(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5611658,
     "sourceId": 9272639,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 91102,
     "modelInstanceId": 68809,
     "sourceId": 81881,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
